{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4c166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "decad16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PANDAS CAN READ IN FILES INTO A DATAFRAME OBJECT\n",
    "df = pd.read_csv('smsspamcollection.tsv',sep='\\t') #TAB SEPARATED FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b130814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FIRST 5 ROWS\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a60f03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WE DONT KNOW HOW TO EXTRACT FEATURES FROM THE MESSAGE\n",
    "#ONLY USE LENGTH AND PUNCT [ALREADY NUMERICAL]\n",
    "\n",
    "#CHECK IF DATA IS MISSING ANYTHING: TRUE -> NULL -> 1\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f769bcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HOW MANY ROWS/RECORDS\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61f49a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ham\n",
       "1        ham\n",
       "2       spam\n",
       "3        ham\n",
       "4        ham\n",
       "5       spam\n",
       "6        ham\n",
       "7        ham\n",
       "8       spam\n",
       "9       spam\n",
       "10       ham\n",
       "11      spam\n",
       "12      spam\n",
       "13       ham\n",
       "14       ham\n",
       "15      spam\n",
       "16       ham\n",
       "17       ham\n",
       "18       ham\n",
       "19      spam\n",
       "20       ham\n",
       "21       ham\n",
       "22       ham\n",
       "23       ham\n",
       "24       ham\n",
       "25       ham\n",
       "26       ham\n",
       "27       ham\n",
       "28       ham\n",
       "29       ham\n",
       "        ... \n",
       "5542     ham\n",
       "5543     ham\n",
       "5544     ham\n",
       "5545     ham\n",
       "5546     ham\n",
       "5547    spam\n",
       "5548     ham\n",
       "5549     ham\n",
       "5550     ham\n",
       "5551     ham\n",
       "5552     ham\n",
       "5553     ham\n",
       "5554     ham\n",
       "5555     ham\n",
       "5556     ham\n",
       "5557     ham\n",
       "5558     ham\n",
       "5559     ham\n",
       "5560     ham\n",
       "5561     ham\n",
       "5562     ham\n",
       "5563     ham\n",
       "5564     ham\n",
       "5565     ham\n",
       "5566    spam\n",
       "5567    spam\n",
       "5568     ham\n",
       "5569     ham\n",
       "5570     ham\n",
       "5571     ham\n",
       "Name: label, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ACCESS SPECIFIC COLUMNS\n",
    "df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b964bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ACCESS UNIQUE VALUES IN A COLUMN\n",
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "935f2839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HOW MANY OF EACH UNIQUE VALUE\n",
    "df['label'].value_countscounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "955e19ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPAM MESSAGES USUALLY LONGER THAN HAM MESSAGES\n",
    "#BEHAVIOUR IN NUMBER OF PUNCTUATION NOT CLEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5951228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT INTO TRAINING AND TESTING SET\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "367ea62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X -> FEATURE DATA\n",
    "X = df[['length', 'punct']]\n",
    "#Y -> LABEL\n",
    "Y = df['label']\n",
    "\n",
    "#30% TESTING #SAME RANDOM_STATE; SAME SPLIT EACH TIME\n",
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(X,Y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00208948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3900, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SHAPE OF DATA: (ROWS, COLS)\n",
    "X_TRAIN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12dc6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE AND TRAIN A ML MODEL\n",
    "\n",
    "#IMPORT\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e9fdf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATE\n",
    "lr_model = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "552a200a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRAIN THE MODEL\n",
    "lr_model.fit(X_TRAIN, Y_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a28d853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST ACCURACY OF MODEL USING TEST DATA\n",
    "\n",
    "\n",
    "#IMPORT\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa0c34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTION RESULTS\n",
    "predictions = lr_model.predict(X_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70af08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRUE VALUES: Y_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b944f034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1404   44]\n",
      " [ 219    5]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>1404</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>219</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ham  spam\n",
       "ham   1404    44\n",
       "spam   219     5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BUILD OUT THE CONFUSION MATRIX\n",
    "print(metrics.confusion_matrix(Y_TEST, predictions))\n",
    "\n",
    "df = pd.DataFrame(metrics.confusion_matrix(Y_TEST,predictions), index=['ham','spam'], columns=['ham','spam'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe1173ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.97      0.91      1448\n",
      "        spam       0.10      0.02      0.04       224\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1672\n",
      "   macro avg       0.48      0.50      0.48      1672\n",
      "weighted avg       0.76      0.84      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5 SPAMS CORRECTLY CLASSIFIED\n",
    "#SHOULD TAKE INTO ACCOUNT TEXT DATA TOO\n",
    "\n",
    "#CLASSIFICATION REPORT\n",
    "print(metrics.classification_report(Y_TEST,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a425135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.27033492822966\n"
     ]
    }
   ],
   "source": [
    "#OVERALL ACCURACY\n",
    "print(100*metrics.accuracy_score(Y_TEST, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a2d8f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1438   10]\n",
      " [ 224    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.99      0.92      1448\n",
      "        spam       0.00      0.00      0.00       224\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1672\n",
      "   macro avg       0.43      0.50      0.46      1672\n",
      "weighted avg       0.75      0.86      0.80      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#USING A NAIVE BAYES MODEL\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_TRAIN, Y_TRAIN)\n",
    "\n",
    "predictions = nb_model.predict(X_TEST)\n",
    "\n",
    "print(metrics.confusion_matrix(Y_TEST, predictions))\n",
    "\n",
    "print(metrics.classification_report(Y_TEST, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45cafb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1373   75]\n",
      " [ 121  103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.95      0.93      1448\n",
      "        spam       0.58      0.46      0.51       224\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1672\n",
      "   macro avg       0.75      0.70      0.72      1672\n",
      "weighted avg       0.87      0.88      0.88      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#USING A SVM MODEL\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(gamma = 'auto')\n",
    "svc_model.fit(X_TRAIN, Y_TRAIN)\n",
    "\n",
    "predictions = svc_model.predict(X_TEST)\n",
    "\n",
    "print(metrics.confusion_matrix(Y_TEST, predictions))\n",
    "\n",
    "print(metrics.classification_report(Y_TEST, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e95153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
