{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18689dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04bde6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt','rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a628f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt','rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c962b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e36014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN-TEST SPLIT ALREADY DONE\n",
    "#LIST OF TUPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa7508c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])#DATA; QUERY; ANSWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86408696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE A VOCABULARY\n",
    "\n",
    "all_data = test_data + train_data\n",
    "\n",
    "#SET\n",
    "vocab = set()\n",
    "\n",
    "for story, question, answer in all_data: #tuple unpacking\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04e23b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0137e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78275530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE ARE LIMITED TO THESE WORDS WHEN ASKING A QUERY\n",
    "vocab_len = len(vocab) + 1 #PLACEHOLDER WHEN USING KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a27728a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOW LONG IS THE LONGEST STORY AND LONGEST QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61d64f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LONGEST STORY\n",
    "all_story_lens = [len(data[0]) for data in all_data]\n",
    "\n",
    "max_story_len = max(all_story_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "868812fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LONGEST QUESTION\n",
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2766007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PART 2: USING KERAS WITH THIS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7a3dd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 02:31:42.418902: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90a0d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a33d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTANTIATE: NO PUNCTUATION FILTERS\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "\n",
    "#CREATE DICTIONARY: WORD:ID_NUMBER\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2e1f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VECTORISATION FOR STORY, QUESTION, ANSWERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "561d6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baef2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dd011d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)\n",
    "train_question_seq = tokenizer.texts_to_sequences(train_question_text)\n",
    "train_answers_seq = tokenizer.texts_to_sequences(train_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30e1fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len, max_question_len=max_question_len):\n",
    "    \n",
    "    #VECTORISE INTO PADDED SEQUENCES\n",
    "    \n",
    "    #STORIES\n",
    "    X = []\n",
    "    \n",
    "    #QUESTIONS\n",
    "    Xq  = []\n",
    "    \n",
    "    #CORRECT ANSWER [YES/NO]\n",
    "    Y = []\n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        #FOR EACH STORY; LIST OF WORD INDICES\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        \n",
    "        #FOR EACH QUESTION; LIST OF WORD INDICES\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        #ANSWER\n",
    "        y = np.zeros(len(word_index)+1)\n",
    "        \n",
    "        #USE NUMPY LOGIC [YES/NO]\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "        \n",
    "    return (pad_sequences(X, maxlen=max_story_len), pad_sequences(Xq,maxlen=max_question_len), np.array(Y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "596bbbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74da4903",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee7d90ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e60d48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ef98540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 503.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d59e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PART 3: CREATING THE MODEL WITH KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d28bf62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.layers.embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tl/ps_r0r591fx137cf06vhn3tm0000gn/T/ipykernel_3271/2152541090.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.layers.embeddings'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53be1f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0231642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b487efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE PLACEHOLDERS USING INPUT\n",
    "\n",
    "#PLACEHOLDER shape = (max_story_len, batch_size)\n",
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b6081da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69439819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 02:31:54.748230: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#INPUT ENCODER M\n",
    "\n",
    "#INPUT GETS EMBEDDED TO A SEQUENCE OF VECTORS\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))#30% OF NEURONS TURNED OFF TO AVOID OVERFITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62d19952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT ENCODER C\n",
    "\n",
    "#INPUT GETS EMBEDDED TO A SEQUENCE OF VECTORS\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))#30% OF NEURONS TURNED OFF TO AVOID OVERFITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aac296da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#M - > SAMPLES, STORY_MAXLEN, EMBEDDING_DIM\n",
    "#C -> SAMPLES, STORY_MAXLEN, MAX_QUESTION_LEN\n",
    "#Q -> SAMPLES, QUERY_MAXLEN, EMBEDDING_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4ab3334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION ENCODER\n",
    "#INPUT GETS EMBEDDED TO A SEQUENCE OF VECTORS\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))#30% OF NEURONS TURNED OFF TO AVOID OVERFITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4138b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PASS IN THE PLACEHOLDERS INTO THE ENCODERS\n",
    "\n",
    "\n",
    "#ENCODED <--- ENCODER(INPUT)\n",
    "#RESULTS\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3f33fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m,question_encoded], axes = (2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "582ff0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD THIS MATCH MATRIX WITH SECOND INPUT VECTOR SEQUENCE\n",
    "response = add([match, input_encoded_c])\n",
    "response = Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20004bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONCATENATE THE MATCH MATRIX WITH QUESTION VECTOR SEQUENCE\n",
    "answer = concatenate([response, question_encoded])\n",
    "answer #CORRECT: (NONE, 6, 220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d43d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REDUCE WITH A RNN: CHOOSE A LSTM\n",
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40194727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREVENT OVERFITTING: DROPOUT\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer) #SAMPLES,VOCAB_SIZE #YES/NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6f777d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn into 0/1 with softmax\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94bd3b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence,question],answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9bb8082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01b53a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PART - 4: TRAIN, EVALUATE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7b1cdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "313/313 [==============================] - 6s 11ms/step - loss: 0.9501 - accuracy: 0.4986 - val_loss: 0.6957 - val_accuracy: 0.4970\n",
      "Epoch 2/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.7111 - accuracy: 0.4999 - val_loss: 0.6947 - val_accuracy: 0.4970\n",
      "Epoch 3/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6994 - accuracy: 0.5034 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
      "Epoch 4/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6970 - accuracy: 0.4926 - val_loss: 0.6939 - val_accuracy: 0.5030\n",
      "Epoch 5/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6962 - accuracy: 0.4923 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 6/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6951 - accuracy: 0.5058 - val_loss: 0.6945 - val_accuracy: 0.4970\n",
      "Epoch 7/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6953 - accuracy: 0.5061 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 8/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6958 - accuracy: 0.4929 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 9/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6952 - accuracy: 0.5017 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 10/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6953 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 11/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6944 - accuracy: 0.5007 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
      "Epoch 12/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6953 - accuracy: 0.4973 - val_loss: 0.6931 - val_accuracy: 0.5030\n",
      "Epoch 13/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6950 - accuracy: 0.4997 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
      "Epoch 14/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6947 - accuracy: 0.5029 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 15/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6952 - accuracy: 0.5046 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 16/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6954 - accuracy: 0.4915 - val_loss: 0.6942 - val_accuracy: 0.4970\n",
      "Epoch 17/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6954 - accuracy: 0.4935 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 18/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6951 - accuracy: 0.4919 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 19/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6951 - accuracy: 0.4966 - val_loss: 0.7000 - val_accuracy: 0.4970\n",
      "Epoch 20/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6950 - accuracy: 0.5036 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 21/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6950 - accuracy: 0.4943 - val_loss: 0.6936 - val_accuracy: 0.5030\n",
      "Epoch 22/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6951 - accuracy: 0.4956 - val_loss: 0.6997 - val_accuracy: 0.4970\n",
      "Epoch 23/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6945 - accuracy: 0.5093 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
      "Epoch 24/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6953 - accuracy: 0.4946 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
      "Epoch 25/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6947 - accuracy: 0.5035 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 26/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6949 - accuracy: 0.4987 - val_loss: 0.6937 - val_accuracy: 0.5030\n",
      "Epoch 27/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6946 - accuracy: 0.5085 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
      "Epoch 28/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6947 - accuracy: 0.5040 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 29/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6945 - accuracy: 0.5032 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
      "Epoch 30/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6949 - accuracy: 0.4996 - val_loss: 0.6963 - val_accuracy: 0.5030\n",
      "Epoch 31/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6955 - accuracy: 0.4923 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 32/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6948 - accuracy: 0.5014 - val_loss: 0.6941 - val_accuracy: 0.4970\n",
      "Epoch 33/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6950 - accuracy: 0.5045 - val_loss: 0.6942 - val_accuracy: 0.4970\n",
      "Epoch 34/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.6948 - accuracy: 0.5032 - val_loss: 0.6941 - val_accuracy: 0.5030\n",
      "Epoch 35/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6951 - accuracy: 0.4960 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 36/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6949 - accuracy: 0.4986 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
      "Epoch 37/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6946 - accuracy: 0.5037 - val_loss: 0.6939 - val_accuracy: 0.5030\n",
      "Epoch 38/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6946 - accuracy: 0.5026 - val_loss: 0.6934 - val_accuracy: 0.4970\n",
      "Epoch 39/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6946 - accuracy: 0.4996 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 40/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6949 - accuracy: 0.4979 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 41/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6950 - accuracy: 0.4960 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 42/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6947 - accuracy: 0.4968 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 43/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6950 - accuracy: 0.4968 - val_loss: 0.6953 - val_accuracy: 0.5030\n",
      "Epoch 44/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6951 - accuracy: 0.4921 - val_loss: 0.6932 - val_accuracy: 0.4790\n",
      "Epoch 45/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6947 - accuracy: 0.5010 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
      "Epoch 46/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6946 - accuracy: 0.5010 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 47/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6946 - accuracy: 0.5011 - val_loss: 0.6946 - val_accuracy: 0.5030\n",
      "Epoch 48/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6947 - accuracy: 0.4963 - val_loss: 0.6945 - val_accuracy: 0.5030\n",
      "Epoch 49/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6944 - accuracy: 0.5054 - val_loss: 0.6937 - val_accuracy: 0.4970\n",
      "Epoch 50/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.6947 - accuracy: 0.4956 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 51/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6941 - accuracy: 0.5112 - val_loss: 0.6939 - val_accuracy: 0.4970\n",
      "Epoch 52/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6952 - accuracy: 0.4968 - val_loss: 0.6932 - val_accuracy: 0.4900\n",
      "Epoch 53/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6940 - accuracy: 0.5080 - val_loss: 0.6954 - val_accuracy: 0.4970\n",
      "Epoch 54/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6942 - accuracy: 0.5084 - val_loss: 0.6969 - val_accuracy: 0.4970\n",
      "Epoch 55/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6947 - accuracy: 0.5037 - val_loss: 0.6938 - val_accuracy: 0.5020\n",
      "Epoch 56/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6942 - accuracy: 0.5036 - val_loss: 0.6955 - val_accuracy: 0.4950\n",
      "Epoch 57/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6944 - accuracy: 0.5066 - val_loss: 0.6943 - val_accuracy: 0.4740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6936 - accuracy: 0.5113 - val_loss: 0.6975 - val_accuracy: 0.5040\n",
      "Epoch 59/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6932 - accuracy: 0.5150 - val_loss: 0.6977 - val_accuracy: 0.5010\n",
      "Epoch 60/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6931 - accuracy: 0.5179 - val_loss: 0.6962 - val_accuracy: 0.4840\n",
      "Epoch 61/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6925 - accuracy: 0.5171 - val_loss: 0.6958 - val_accuracy: 0.4840\n",
      "Epoch 62/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6916 - accuracy: 0.5303 - val_loss: 0.6964 - val_accuracy: 0.4800\n",
      "Epoch 63/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6912 - accuracy: 0.5252 - val_loss: 0.6954 - val_accuracy: 0.4870\n",
      "Epoch 64/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6873 - accuracy: 0.5437 - val_loss: 0.6934 - val_accuracy: 0.5160\n",
      "Epoch 65/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6836 - accuracy: 0.5562 - val_loss: 0.6979 - val_accuracy: 0.5220\n",
      "Epoch 66/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6758 - accuracy: 0.5756 - val_loss: 0.6772 - val_accuracy: 0.5560\n",
      "Epoch 67/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6622 - accuracy: 0.5975 - val_loss: 0.6634 - val_accuracy: 0.6070\n",
      "Epoch 68/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6526 - accuracy: 0.6188 - val_loss: 0.6477 - val_accuracy: 0.6280\n",
      "Epoch 69/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6407 - accuracy: 0.6375 - val_loss: 0.6319 - val_accuracy: 0.6390\n",
      "Epoch 70/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6334 - accuracy: 0.6508 - val_loss: 0.6262 - val_accuracy: 0.6570\n",
      "Epoch 71/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.6216 - accuracy: 0.6614 - val_loss: 0.6150 - val_accuracy: 0.6590\n",
      "Epoch 72/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6138 - accuracy: 0.6685 - val_loss: 0.6065 - val_accuracy: 0.6820\n",
      "Epoch 73/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6102 - accuracy: 0.6766 - val_loss: 0.5953 - val_accuracy: 0.6850\n",
      "Epoch 74/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.5961 - accuracy: 0.6888 - val_loss: 0.5764 - val_accuracy: 0.6910\n",
      "Epoch 75/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.5833 - accuracy: 0.6993 - val_loss: 0.5736 - val_accuracy: 0.7030\n",
      "Epoch 76/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.5659 - accuracy: 0.7141 - val_loss: 0.5511 - val_accuracy: 0.7300\n",
      "Epoch 77/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.5561 - accuracy: 0.7218 - val_loss: 0.5226 - val_accuracy: 0.7550\n",
      "Epoch 78/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.5314 - accuracy: 0.7479 - val_loss: 0.5163 - val_accuracy: 0.7810\n",
      "Epoch 79/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.5059 - accuracy: 0.7620 - val_loss: 0.4751 - val_accuracy: 0.7840\n",
      "Epoch 80/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4905 - accuracy: 0.7780 - val_loss: 0.4524 - val_accuracy: 0.8070\n",
      "Epoch 81/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4710 - accuracy: 0.7882 - val_loss: 0.4345 - val_accuracy: 0.8070\n",
      "Epoch 82/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4578 - accuracy: 0.7980 - val_loss: 0.4295 - val_accuracy: 0.8080\n",
      "Epoch 83/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4521 - accuracy: 0.8018 - val_loss: 0.4108 - val_accuracy: 0.8170\n",
      "Epoch 84/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4421 - accuracy: 0.8060 - val_loss: 0.4378 - val_accuracy: 0.8020\n",
      "Epoch 85/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4306 - accuracy: 0.8137 - val_loss: 0.4033 - val_accuracy: 0.8240\n",
      "Epoch 86/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4264 - accuracy: 0.8194 - val_loss: 0.4081 - val_accuracy: 0.8190\n",
      "Epoch 87/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4175 - accuracy: 0.8213 - val_loss: 0.3971 - val_accuracy: 0.8190\n",
      "Epoch 88/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4060 - accuracy: 0.8294 - val_loss: 0.3928 - val_accuracy: 0.8200\n",
      "Epoch 89/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.4035 - accuracy: 0.8262 - val_loss: 0.3944 - val_accuracy: 0.8210\n",
      "Epoch 90/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3930 - accuracy: 0.8317 - val_loss: 0.4023 - val_accuracy: 0.8200\n",
      "Epoch 91/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3818 - accuracy: 0.8385 - val_loss: 0.3814 - val_accuracy: 0.8350\n",
      "Epoch 92/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3793 - accuracy: 0.8398 - val_loss: 0.3843 - val_accuracy: 0.8250\n",
      "Epoch 93/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3711 - accuracy: 0.8442 - val_loss: 0.4051 - val_accuracy: 0.8170\n",
      "Epoch 94/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3688 - accuracy: 0.8456 - val_loss: 0.4881 - val_accuracy: 0.7790\n",
      "Epoch 95/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3608 - accuracy: 0.8482 - val_loss: 0.3683 - val_accuracy: 0.8350\n",
      "Epoch 96/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3575 - accuracy: 0.8481 - val_loss: 0.3717 - val_accuracy: 0.8330\n",
      "Epoch 97/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3568 - accuracy: 0.8497 - val_loss: 0.3684 - val_accuracy: 0.8220\n",
      "Epoch 98/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3442 - accuracy: 0.8538 - val_loss: 0.3688 - val_accuracy: 0.8260\n",
      "Epoch 99/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3514 - accuracy: 0.8522 - val_loss: 0.3727 - val_accuracy: 0.8200\n",
      "Epoch 100/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3408 - accuracy: 0.8541 - val_loss: 0.3729 - val_accuracy: 0.8220\n",
      "Epoch 101/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3374 - accuracy: 0.8563 - val_loss: 0.3583 - val_accuracy: 0.8320\n",
      "Epoch 102/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3365 - accuracy: 0.8586 - val_loss: 0.3600 - val_accuracy: 0.8250\n",
      "Epoch 103/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3285 - accuracy: 0.8607 - val_loss: 0.3675 - val_accuracy: 0.8340\n",
      "Epoch 104/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3228 - accuracy: 0.8622 - val_loss: 0.3690 - val_accuracy: 0.8320\n",
      "Epoch 105/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3285 - accuracy: 0.8602 - val_loss: 0.3910 - val_accuracy: 0.8300\n",
      "Epoch 106/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3281 - accuracy: 0.8626 - val_loss: 0.3598 - val_accuracy: 0.8330\n",
      "Epoch 107/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3167 - accuracy: 0.8666 - val_loss: 0.3877 - val_accuracy: 0.8250\n",
      "Epoch 108/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.3209 - accuracy: 0.8614 - val_loss: 0.4179 - val_accuracy: 0.8110\n",
      "Epoch 109/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.3214 - accuracy: 0.8620 - val_loss: 0.3701 - val_accuracy: 0.8210\n",
      "Epoch 110/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3176 - accuracy: 0.8627 - val_loss: 0.3689 - val_accuracy: 0.8170\n",
      "Epoch 111/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3107 - accuracy: 0.8640 - val_loss: 0.3891 - val_accuracy: 0.8270\n",
      "Epoch 112/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3127 - accuracy: 0.8654 - val_loss: 0.3874 - val_accuracy: 0.8260\n",
      "Epoch 113/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3120 - accuracy: 0.8628 - val_loss: 0.3672 - val_accuracy: 0.8290\n",
      "Epoch 114/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3209 - accuracy: 0.8619 - val_loss: 0.3729 - val_accuracy: 0.8320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.3063 - accuracy: 0.8685 - val_loss: 0.4075 - val_accuracy: 0.8150\n",
      "Epoch 116/250\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3069 - accuracy: 0.8662 - val_loss: 0.3685 - val_accuracy: 0.8300\n",
      "Epoch 117/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3074 - accuracy: 0.8699 - val_loss: 0.3789 - val_accuracy: 0.8330\n",
      "Epoch 118/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3067 - accuracy: 0.8696 - val_loss: 0.3680 - val_accuracy: 0.8260\n",
      "Epoch 119/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3054 - accuracy: 0.8698 - val_loss: 0.3824 - val_accuracy: 0.8270\n",
      "Epoch 120/250\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3017 - accuracy: 0.8670 - val_loss: 0.3858 - val_accuracy: 0.8240\n",
      "Epoch 121/250\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3046 - accuracy: 0.8678 - val_loss: 0.4051 - val_accuracy: 0.8190\n",
      "Epoch 122/250\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3001 - accuracy: 0.8701 - val_loss: 0.3671 - val_accuracy: 0.8260\n",
      "Epoch 123/250\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2973 - accuracy: 0.8690 - val_loss: 0.3813 - val_accuracy: 0.8300\n",
      "Epoch 124/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3046 - accuracy: 0.8694 - val_loss: 0.3836 - val_accuracy: 0.8330\n",
      "Epoch 125/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2988 - accuracy: 0.8702 - val_loss: 0.3880 - val_accuracy: 0.8220\n",
      "Epoch 126/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3000 - accuracy: 0.8712 - val_loss: 0.3841 - val_accuracy: 0.8270\n",
      "Epoch 127/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2969 - accuracy: 0.8695 - val_loss: 0.3784 - val_accuracy: 0.8280\n",
      "Epoch 128/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2981 - accuracy: 0.8722 - val_loss: 0.3808 - val_accuracy: 0.8320\n",
      "Epoch 129/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2949 - accuracy: 0.8727 - val_loss: 0.3996 - val_accuracy: 0.8250\n",
      "Epoch 130/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2976 - accuracy: 0.8710 - val_loss: 0.3757 - val_accuracy: 0.8250\n",
      "Epoch 131/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3015 - accuracy: 0.8714 - val_loss: 0.3864 - val_accuracy: 0.8290\n",
      "Epoch 132/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2917 - accuracy: 0.8756 - val_loss: 0.3933 - val_accuracy: 0.8260\n",
      "Epoch 133/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2934 - accuracy: 0.8730 - val_loss: 0.4160 - val_accuracy: 0.8220\n",
      "Epoch 134/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2892 - accuracy: 0.8732 - val_loss: 0.4153 - val_accuracy: 0.8240\n",
      "Epoch 135/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2948 - accuracy: 0.8738 - val_loss: 0.4073 - val_accuracy: 0.8190\n",
      "Epoch 136/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2857 - accuracy: 0.8764 - val_loss: 0.4020 - val_accuracy: 0.8200\n",
      "Epoch 137/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2876 - accuracy: 0.8791 - val_loss: 0.4067 - val_accuracy: 0.8240\n",
      "Epoch 138/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2895 - accuracy: 0.8751 - val_loss: 0.3891 - val_accuracy: 0.8190\n",
      "Epoch 139/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2940 - accuracy: 0.8711 - val_loss: 0.3874 - val_accuracy: 0.8350\n",
      "Epoch 140/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2881 - accuracy: 0.8748 - val_loss: 0.4524 - val_accuracy: 0.8190\n",
      "Epoch 141/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2792 - accuracy: 0.8756 - val_loss: 0.3845 - val_accuracy: 0.8270\n",
      "Epoch 142/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2824 - accuracy: 0.8822 - val_loss: 0.4139 - val_accuracy: 0.8210\n",
      "Epoch 143/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2893 - accuracy: 0.8727 - val_loss: 0.3834 - val_accuracy: 0.8370\n",
      "Epoch 144/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2882 - accuracy: 0.8748 - val_loss: 0.4199 - val_accuracy: 0.8230\n",
      "Epoch 145/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2856 - accuracy: 0.8793 - val_loss: 0.4091 - val_accuracy: 0.8320\n",
      "Epoch 146/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2850 - accuracy: 0.8766 - val_loss: 0.4555 - val_accuracy: 0.8140\n",
      "Epoch 147/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2898 - accuracy: 0.8786 - val_loss: 0.4382 - val_accuracy: 0.8320\n",
      "Epoch 148/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2810 - accuracy: 0.8770 - val_loss: 0.4377 - val_accuracy: 0.8170\n",
      "Epoch 149/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2857 - accuracy: 0.8755 - val_loss: 0.4081 - val_accuracy: 0.8220\n",
      "Epoch 150/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2777 - accuracy: 0.8798 - val_loss: 0.4088 - val_accuracy: 0.8230\n",
      "Epoch 151/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2789 - accuracy: 0.8799 - val_loss: 0.3898 - val_accuracy: 0.8250\n",
      "Epoch 152/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2792 - accuracy: 0.8778 - val_loss: 0.4161 - val_accuracy: 0.8240\n",
      "Epoch 153/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2800 - accuracy: 0.8796 - val_loss: 0.3951 - val_accuracy: 0.8220\n",
      "Epoch 154/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2779 - accuracy: 0.8817 - val_loss: 0.3975 - val_accuracy: 0.8340\n",
      "Epoch 155/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2764 - accuracy: 0.8789 - val_loss: 0.4064 - val_accuracy: 0.8230\n",
      "Epoch 156/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2795 - accuracy: 0.8773 - val_loss: 0.4053 - val_accuracy: 0.8280\n",
      "Epoch 157/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2725 - accuracy: 0.8832 - val_loss: 0.4300 - val_accuracy: 0.8270\n",
      "Epoch 158/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2744 - accuracy: 0.8832 - val_loss: 0.4376 - val_accuracy: 0.8190\n",
      "Epoch 159/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2670 - accuracy: 0.8829 - val_loss: 0.4747 - val_accuracy: 0.8210\n",
      "Epoch 160/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2737 - accuracy: 0.8851 - val_loss: 0.4359 - val_accuracy: 0.8320\n",
      "Epoch 161/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2758 - accuracy: 0.8809 - val_loss: 0.4394 - val_accuracy: 0.8200\n",
      "Epoch 162/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2740 - accuracy: 0.8808 - val_loss: 0.4241 - val_accuracy: 0.8280\n",
      "Epoch 163/250\n",
      "313/313 [==============================] - 2s 8ms/step - loss: 0.2660 - accuracy: 0.8869 - val_loss: 0.4508 - val_accuracy: 0.8230\n",
      "Epoch 164/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2736 - accuracy: 0.8814 - val_loss: 0.4337 - val_accuracy: 0.8230\n",
      "Epoch 165/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2685 - accuracy: 0.8824 - val_loss: 0.4422 - val_accuracy: 0.8290\n",
      "Epoch 166/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2735 - accuracy: 0.8832 - val_loss: 0.4285 - val_accuracy: 0.8250\n",
      "Epoch 167/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2703 - accuracy: 0.8845 - val_loss: 0.4144 - val_accuracy: 0.8360\n",
      "Epoch 168/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2679 - accuracy: 0.8868 - val_loss: 0.4511 - val_accuracy: 0.8210\n",
      "Epoch 169/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2710 - accuracy: 0.8866 - val_loss: 0.4565 - val_accuracy: 0.8230\n",
      "Epoch 170/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2719 - accuracy: 0.8827 - val_loss: 0.4335 - val_accuracy: 0.8350\n",
      "Epoch 171/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2653 - accuracy: 0.8849 - val_loss: 0.4448 - val_accuracy: 0.8190\n",
      "Epoch 172/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2677 - accuracy: 0.8857 - val_loss: 0.4058 - val_accuracy: 0.8380\n",
      "Epoch 173/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2679 - accuracy: 0.8870 - val_loss: 0.4189 - val_accuracy: 0.8320\n",
      "Epoch 174/250\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2621 - accuracy: 0.8885 - val_loss: 0.4385 - val_accuracy: 0.8290\n",
      "Epoch 175/250\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2677 - accuracy: 0.8870 - val_loss: 0.4656 - val_accuracy: 0.8230\n",
      "Epoch 176/250\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2608 - accuracy: 0.8880 - val_loss: 0.4280 - val_accuracy: 0.8220\n",
      "Epoch 177/250\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2676 - accuracy: 0.8857 - val_loss: 0.4229 - val_accuracy: 0.8340\n",
      "Epoch 178/250\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2613 - accuracy: 0.8896 - val_loss: 0.4447 - val_accuracy: 0.8350\n",
      "Epoch 179/250\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2636 - accuracy: 0.8882 - val_loss: 0.4492 - val_accuracy: 0.8200\n",
      "Epoch 180/250\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2612 - accuracy: 0.8876 - val_loss: 0.4674 - val_accuracy: 0.8150\n",
      "Epoch 181/250\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2613 - accuracy: 0.8872 - val_loss: 0.4570 - val_accuracy: 0.8330\n",
      "Epoch 182/250\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2583 - accuracy: 0.8868 - val_loss: 0.4862 - val_accuracy: 0.8260\n",
      "Epoch 183/250\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2545 - accuracy: 0.8913 - val_loss: 0.4733 - val_accuracy: 0.8260\n",
      "Epoch 184/250\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2602 - accuracy: 0.8831 - val_loss: 0.4530 - val_accuracy: 0.8250\n",
      "Epoch 185/250\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2566 - accuracy: 0.8888 - val_loss: 0.4472 - val_accuracy: 0.8270\n",
      "Epoch 186/250\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2601 - accuracy: 0.8878 - val_loss: 0.5313 - val_accuracy: 0.8160\n",
      "Epoch 187/250\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2582 - accuracy: 0.8898 - val_loss: 0.5530 - val_accuracy: 0.8210\n",
      "Epoch 188/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2546 - accuracy: 0.8927 - val_loss: 0.4823 - val_accuracy: 0.8270\n",
      "Epoch 189/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2536 - accuracy: 0.8899 - val_loss: 0.5087 - val_accuracy: 0.8180\n",
      "Epoch 190/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2539 - accuracy: 0.8917 - val_loss: 0.4702 - val_accuracy: 0.8320\n",
      "Epoch 191/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2606 - accuracy: 0.8895 - val_loss: 0.4689 - val_accuracy: 0.8360\n",
      "Epoch 192/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2550 - accuracy: 0.8908 - val_loss: 0.4580 - val_accuracy: 0.8290\n",
      "Epoch 193/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2540 - accuracy: 0.8933 - val_loss: 0.4796 - val_accuracy: 0.8290\n",
      "Epoch 194/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2496 - accuracy: 0.8921 - val_loss: 0.4874 - val_accuracy: 0.8200\n",
      "Epoch 195/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2521 - accuracy: 0.8936 - val_loss: 0.4804 - val_accuracy: 0.8330\n",
      "Epoch 196/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2520 - accuracy: 0.8911 - val_loss: 0.4963 - val_accuracy: 0.8350\n",
      "Epoch 197/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2563 - accuracy: 0.8926 - val_loss: 0.5190 - val_accuracy: 0.8080\n",
      "Epoch 198/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2465 - accuracy: 0.8978 - val_loss: 0.5430 - val_accuracy: 0.8160\n",
      "Epoch 199/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2508 - accuracy: 0.8966 - val_loss: 0.4595 - val_accuracy: 0.8330\n",
      "Epoch 200/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2438 - accuracy: 0.8973 - val_loss: 0.4601 - val_accuracy: 0.8270\n",
      "Epoch 201/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2605 - accuracy: 0.8912 - val_loss: 0.4673 - val_accuracy: 0.8280\n",
      "Epoch 202/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2419 - accuracy: 0.9013 - val_loss: 0.5061 - val_accuracy: 0.8220\n",
      "Epoch 203/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2498 - accuracy: 0.8964 - val_loss: 0.4814 - val_accuracy: 0.8230\n",
      "Epoch 204/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2401 - accuracy: 0.8974 - val_loss: 0.4985 - val_accuracy: 0.8360\n",
      "Epoch 205/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2448 - accuracy: 0.8966 - val_loss: 0.4877 - val_accuracy: 0.8270\n",
      "Epoch 206/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2459 - accuracy: 0.8976 - val_loss: 0.4937 - val_accuracy: 0.8290\n",
      "Epoch 207/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2445 - accuracy: 0.8982 - val_loss: 0.5180 - val_accuracy: 0.8240\n",
      "Epoch 208/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2449 - accuracy: 0.8980 - val_loss: 0.4759 - val_accuracy: 0.8240\n",
      "Epoch 209/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2434 - accuracy: 0.8984 - val_loss: 0.4822 - val_accuracy: 0.8310\n",
      "Epoch 210/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2404 - accuracy: 0.9005 - val_loss: 0.5061 - val_accuracy: 0.8230\n",
      "Epoch 211/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2414 - accuracy: 0.8959 - val_loss: 0.4830 - val_accuracy: 0.8160\n",
      "Epoch 212/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2425 - accuracy: 0.8976 - val_loss: 0.5063 - val_accuracy: 0.8240\n",
      "Epoch 213/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2381 - accuracy: 0.8989 - val_loss: 0.5096 - val_accuracy: 0.8300\n",
      "Epoch 214/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2367 - accuracy: 0.9027 - val_loss: 0.5245 - val_accuracy: 0.8230\n",
      "Epoch 215/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2411 - accuracy: 0.8986 - val_loss: 0.4813 - val_accuracy: 0.8270\n",
      "Epoch 216/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2477 - accuracy: 0.8967 - val_loss: 0.5059 - val_accuracy: 0.8200\n",
      "Epoch 217/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2302 - accuracy: 0.9031 - val_loss: 0.5116 - val_accuracy: 0.8220\n",
      "Epoch 218/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2347 - accuracy: 0.9001 - val_loss: 0.5021 - val_accuracy: 0.8210\n",
      "Epoch 219/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2307 - accuracy: 0.9005 - val_loss: 0.5039 - val_accuracy: 0.8300\n",
      "Epoch 220/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2324 - accuracy: 0.9050 - val_loss: 0.5061 - val_accuracy: 0.8110\n",
      "Epoch 221/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2267 - accuracy: 0.9047 - val_loss: 0.5180 - val_accuracy: 0.8170\n",
      "Epoch 222/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2308 - accuracy: 0.9039 - val_loss: 0.5075 - val_accuracy: 0.8250\n",
      "Epoch 223/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2332 - accuracy: 0.9021 - val_loss: 0.4896 - val_accuracy: 0.8250\n",
      "Epoch 224/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2284 - accuracy: 0.9035 - val_loss: 0.5405 - val_accuracy: 0.8260\n",
      "Epoch 225/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2230 - accuracy: 0.9057 - val_loss: 0.5090 - val_accuracy: 0.8300\n",
      "Epoch 226/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2285 - accuracy: 0.9043 - val_loss: 0.5678 - val_accuracy: 0.8130\n",
      "Epoch 227/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2342 - accuracy: 0.9005 - val_loss: 0.4873 - val_accuracy: 0.8210\n",
      "Epoch 228/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2309 - accuracy: 0.9024 - val_loss: 0.5630 - val_accuracy: 0.8180\n",
      "Epoch 229/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2308 - accuracy: 0.9039 - val_loss: 0.5955 - val_accuracy: 0.8140\n",
      "Epoch 230/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2251 - accuracy: 0.9066 - val_loss: 0.5219 - val_accuracy: 0.8220\n",
      "Epoch 231/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2198 - accuracy: 0.9079 - val_loss: 0.5369 - val_accuracy: 0.8220\n",
      "Epoch 232/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2212 - accuracy: 0.9072 - val_loss: 0.5292 - val_accuracy: 0.8230\n",
      "Epoch 233/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2268 - accuracy: 0.9064 - val_loss: 0.5576 - val_accuracy: 0.8060\n",
      "Epoch 234/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2203 - accuracy: 0.9064 - val_loss: 0.5191 - val_accuracy: 0.8180\n",
      "Epoch 235/250\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2200 - accuracy: 0.9090 - val_loss: 0.5378 - val_accuracy: 0.8230\n",
      "Epoch 236/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2260 - accuracy: 0.9065 - val_loss: 0.5675 - val_accuracy: 0.8170\n",
      "Epoch 237/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2232 - accuracy: 0.9044 - val_loss: 0.5254 - val_accuracy: 0.8170\n",
      "Epoch 238/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2142 - accuracy: 0.9085 - val_loss: 0.5635 - val_accuracy: 0.8230\n",
      "Epoch 239/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2172 - accuracy: 0.9096 - val_loss: 0.5822 - val_accuracy: 0.8250\n",
      "Epoch 240/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2234 - accuracy: 0.9096 - val_loss: 0.5660 - val_accuracy: 0.8230\n",
      "Epoch 241/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2186 - accuracy: 0.9085 - val_loss: 0.5403 - val_accuracy: 0.8200\n",
      "Epoch 242/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2217 - accuracy: 0.9071 - val_loss: 0.5781 - val_accuracy: 0.8190\n",
      "Epoch 243/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2196 - accuracy: 0.9066 - val_loss: 0.5474 - val_accuracy: 0.8190\n",
      "Epoch 244/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2179 - accuracy: 0.9096 - val_loss: 0.5691 - val_accuracy: 0.8190\n",
      "Epoch 245/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2094 - accuracy: 0.9108 - val_loss: 0.5777 - val_accuracy: 0.8190\n",
      "Epoch 246/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2152 - accuracy: 0.9108 - val_loss: 0.5359 - val_accuracy: 0.8320\n",
      "Epoch 247/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2095 - accuracy: 0.9143 - val_loss: 0.5752 - val_accuracy: 0.8220\n",
      "Epoch 248/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2061 - accuracy: 0.9142 - val_loss: 0.6223 - val_accuracy: 0.8210\n",
      "Epoch 249/250\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.2120 - accuracy: 0.9145 - val_loss: 0.5991 - val_accuracy: 0.8190\n",
      "Epoch 250/250\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2122 - accuracy: 0.9100 - val_loss: 0.5581 - val_accuracy: 0.8160\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train, queries_train], answers_train, batch_size=32,epochs=250,validation_data = ([inputs_test, queries_test],answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd91c85e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tl/ps_r0r591fx137cf06vhn3tm0000gn/T/ipykernel_3271/339245921.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#PREDICT RESULTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpred_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "#EVALUATING ON GIVEN TEST SET\n",
    "\n",
    "\n",
    "#PREDICT RESULTS\n",
    "pred_results = history.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data -> list of tuples [story, question, answer]\n",
    "#pred_results has probabilities for every single word\n",
    "\n",
    "#max probability\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "#print the word\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3463673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANSWER = \n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e8671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROBABILITY OF BEING SURE OF THAT ANSWER\n",
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR YOUR OWN STORIES; YOU CAN ONLY USE WORDS FROM THAT VOCABULARY\n",
    "\n",
    "#SPACE BEFORE AND AFTER PUNCTUATION: SAME FORMAT AS TRAIN_DATA\n",
    "my_story = \"John left the kitches . Sandra dropped the football in tthe garden .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9758b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = 'Is the football in the garden ?' #SAME FORMAT AS TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [(my_story.split(), my_question.split(), 'yes')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ebf0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VECTORIZED\n",
    "my_story, my_ques, my_ans = vectorize_stories(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcaebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICT ONLY AFTER STORY AND QUESTION\n",
    "pred_results = model.predict(([my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f206985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df8e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bc118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a38a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c794cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c8d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34439624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8139e7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339420d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42820ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99bc664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd78c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
